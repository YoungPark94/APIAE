{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "from APIAE import DynNet, GenNet, APIAE\n",
    "import matplotlib.patches as patches\n",
    "from IPython.display import HTML\n",
    "import pickle\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\" # which GPU devices to use\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build APIAE\n",
    "params_inference = \\\n",
    "dict(n_x = 16**2, # dimension of x; observation\n",
    "n_z = 2, # dimension of z; latent space\n",
    "n_u = 1, # dimension of u; control\n",
    "\n",
    "K = 10, # the number of time steps\n",
    "L = 100, # the number of trajectory sampled\n",
    "R = 10,# the number of improvements\n",
    "\n",
    "dt = .1, # time interval\n",
    "ur = .3, # update rate \n",
    "lr = 0.001 # learning rate\n",
    "    )\n",
    "apiae_inference = APIAE(**params_inference)\n",
    "\n",
    "# Build APIAE\n",
    "params_planner = \\\n",
    "dict(n_x = 16**2, # dimension of x; observation\n",
    "n_z = 2, # dimension of z; latent space\n",
    "n_u = 1, # dimension of u; control\n",
    "\n",
    "K = 50, # the number of time steps\n",
    "L = 10000, # the number of trajectory sampled\n",
    "R = 30,# the number of improvements\n",
    "\n",
    "dt = .1, # time interval\n",
    "ur = .3, # update rate \n",
    "lr = 0.001, # learning rate\n",
    "isPlanner = True\n",
    "    )\n",
    "apiae_planner = APIAE(**params_planner)\n",
    "\n",
    "# Set parameters\n",
    "K_inference = params_inference['K']\n",
    "K_planner = params_planner['K']\n",
    "dt_inference = params_planner['dt']\n",
    "dt_planner = params_planner['dt']\n",
    "n_x = params_inference['n_x']\n",
    "n_z = params_inference['n_z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiae_inference.restoreWeights(filename='./weights_demo.pkl')\n",
    "apiae_planner.restoreWeights(filename='./weights_demo.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Sequences\n",
    "file = open(\"pendulum_zero.pkl\",'rb')\n",
    "DATA = pickle.load(file, encoding='latin1')\n",
    "X0 = DATA[0][:,:,0:int(K_inference*dt_inference/0.01):int(dt_inference/0.01),:,:] # observe first sequence\n",
    "Xf = DATA[0][:,:,int((K_inference-1)*dt_inference/0.01):-1:int(dt_planner/0.01),:,:]\n",
    "file.close()\n",
    "\n",
    "# The guidance image\n",
    "Xref = np.zeros((16,16))\n",
    "for i in range(0,16):\n",
    "    Xref[i,:] = 16./(i+3) # swing up\n",
    "Xref = (Xref - np.min(Xref)) / (np.max(Xref) - np.min(Xref))\n",
    "\n",
    "# Show guidance image\n",
    "plt.close()\n",
    "plt.figure()\n",
    "plt.imshow(Xref)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference of the latent space trajectory for the given sequence of observation\n",
    "museq0 = apiae_inference.sess.run((apiae_inference.museq_list), feed_dict={apiae_inference.xseq: X0})\n",
    "museq0_reshape = np.reshape(museq0[-1][0,0,:,:,0],(K_inference,n_z))\n",
    "xtemp = apiae_inference.sess.run(apiae_inference.genNet.x_out,feed_dict={apiae_inference.genNet.z_in:museq0_reshape})\n",
    "xrecon = np.reshape(xtemp, (-1,16,16))\n",
    "\n",
    "# Plan\n",
    "Xobjective = np.tile(Xref.reshape((1,1,1,256,1)),(1,1,K_planner,1,1)) # Define obejctive image\n",
    "museq_planner = apiae_planner.sess.run(apiae_planner.museq_list,\n",
    "                feed_dict={apiae_planner.xseq: Xobjective, apiae_planner.mu0:museq0[-1][:,:,-1:,:,:]})\n",
    "museq_planner_reshape = np.reshape(museq_planner[-1][0,0,:,:,0],(K_planner,n_z))\n",
    "xtemp = apiae_planner.sess.run(apiae_planner.genNet.x_out,feed_dict={apiae_planner.genNet.z_in:museq_planner_reshape})\n",
    "xplan = np.reshape(xtemp, (-1,16,16))\n",
    "\n",
    "# Prediction (Learned Dynamics)\n",
    "z_pred = np.zeros((K_planner,2))\n",
    "z_pred[0,:] = museq0[-1][0,0,-1,:,0]\n",
    "for t in range(K_planner-1):\n",
    "    dz_pred = apiae_planner.sess.run(apiae_planner.dynNet.zdot_out, \\\n",
    "                 feed_dict={apiae_planner.dynNet.z_in:z_pred[t:t+1,:]})*dt_planner\n",
    "    z_pred[t+1,:] = z_pred[t,:] + dz_pred\n",
    "\n",
    "xtemp = apiae_planner.sess.run(apiae_planner.genNet.x_out,feed_dict={apiae_planner.genNet.z_in:z_pred})\n",
    "xpred = np.reshape(xtemp, (-1,16,16))\n",
    "\n",
    "# Draw Results\n",
    "plt.close()\n",
    "plt.figure()\n",
    "plt.plot(museq0_reshape[0,0],museq0_reshape[0,1],'k.') # inference\n",
    "plt.plot(museq0_reshape[:,0],museq0_reshape[:,1],'k-') # inference\n",
    "plt.plot(museq_planner_reshape[0,0],museq_planner_reshape[0,1],'r.') # planning\n",
    "plt.plot(museq_planner_reshape[:,0],museq_planner_reshape[:,1],'r-') # planning\n",
    "plt.plot(z_pred[0,0],z_pred[0,1],'b.') # generative\n",
    "plt.plot(z_pred[:,0],z_pred[:,1],'b-') # generative\n",
    "plt.grid()\n",
    "plt.xlabel('z1')\n",
    "plt.ylabel('z2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw Animation \n",
    "ims_planner = []\n",
    "fig_planner, (ax1,ax2,ax3) = plt.subplots(1,3, figsize=(45,15))\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "ax3.set_xticks([])\n",
    "ax3.set_yticks([])\n",
    "plt.tight_layout()\n",
    "\n",
    "ax1.add_patch(\n",
    "    patches.Rectangle(\n",
    "        (-0.35, -0.4),\n",
    "        15.7,\n",
    "        15.8,\n",
    "        fill=False,\n",
    "        edgecolor=\"blue\",\n",
    "        linewidth=20\n",
    "    )\n",
    ")\n",
    "ax2.add_patch(\n",
    "    patches.Rectangle(\n",
    "        (-0.35, -0.4),\n",
    "        15.7,\n",
    "        15.8,\n",
    "        fill=False,\n",
    "        edgecolor=\"blue\",\n",
    "        linewidth=20\n",
    "    )\n",
    ")\n",
    "ax3.add_patch(\n",
    "    patches.Rectangle(\n",
    "        (-0.35, -0.4),\n",
    "        15.7,\n",
    "        15.8,\n",
    "        fill=False,\n",
    "        edgecolor=\"blue\",\n",
    "        linewidth=20\n",
    "    )\n",
    ")\n",
    "for t in range(K_inference):\n",
    "    im1 = ax1.imshow(X0[0,0,t,:,0].reshape(16,16), animated=True)\n",
    "    imtext1 = ax1.text(.2,1,'Ground Truth',fontsize=70,color='white')\n",
    "    im2 = ax2.imshow(xrecon[t,:,:], animated=True)\n",
    "    imtext2 = ax2.text(.2,1,'Reconstruction',fontsize=70,color='white')\n",
    "    im3 = ax3.imshow(xrecon[t,:,:], animated=True)\n",
    "    imtext3 = ax3.text(.2,1,'Reconstruction',fontsize=70,color='white')\n",
    "    ims_planner.append([im1,imtext1,im2,imtext2,im3,imtext3])\n",
    "\n",
    "im_ani_planner = animation.ArtistAnimation(fig_planner, ims_planner, interval=200,repeat_delay=100)  \n",
    "im_ani_planner.save('./inference.mp4')         \n",
    "HTML(im_ani_planner.to_html5_video())     \n",
    "    \n",
    "    \n",
    "ims_planner = []\n",
    "fig_planner, (ax1,ax2,ax3) = plt.subplots(1,3, figsize=(45,15))\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "ax3.set_xticks([])\n",
    "ax3.set_yticks([])\n",
    "plt.tight_layout()    \n",
    "ax1.add_patch(\n",
    "    patches.Rectangle(\n",
    "        (-0.35, -0.4),\n",
    "        15.7,\n",
    "        15.8,\n",
    "        fill=False,\n",
    "        edgecolor=\"blue\",\n",
    "        linewidth=20\n",
    "    )\n",
    ")\n",
    "ax2.add_patch(\n",
    "    patches.Rectangle(\n",
    "        (-0.35, -0.4),\n",
    "        15.7,\n",
    "        15.8,\n",
    "        fill=False,\n",
    "        edgecolor=\"red\",\n",
    "        linewidth=20\n",
    "    )\n",
    ")\n",
    "ax3.add_patch(\n",
    "    patches.Rectangle(\n",
    "        (-0.35, -0.4),\n",
    "        15.7,\n",
    "        15.8,\n",
    "        fill=False,\n",
    "        edgecolor=\"red\",\n",
    "        linewidth=20\n",
    "    )\n",
    ")\n",
    "for t in range(1,K_planner):\n",
    "    im1 = ax1.imshow(Xf[0,0,t,:,0].reshape(16,16), animated=True)\n",
    "    imtext1 = ax1.text(.2,1,'Ground Truth',fontsize=70,color='white')\n",
    "    im2 = ax2.imshow(xpred[t,:,:], animated=True)\n",
    "    imtext2 = ax2.text(.2,1,'Prediction',fontsize=70,color='white')\n",
    "    im3 = ax3.imshow(xplan[t,:,:], animated=True)\n",
    "    imtext3 = ax3.text(.2,1,'Planning',fontsize=70,color='white')\n",
    "    ims_planner.append([im1,imtext1,im2,imtext2,im3,imtext3])\n",
    "    \n",
    "im_ani_planner = animation.ArtistAnimation(fig_planner, ims_planner, interval=200,repeat_delay=100)  \n",
    "im_ani_planner.save('./planning.mp4')         \n",
    "HTML(im_ani_planner.to_html5_video()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
